# DATA STRUCTURES - ANSWERS TO QUESTIONS 41-50

**Source:** Questions from 13.txt (Questions 41-50)  
**Category:** Data Structures - Trees and Hash Tables  
**Level:** Beginner

## TREES (ADVANCED CONCEPTS)

### 41. What are the types of binary trees? (Google, Amazon)

**Answer:**

**1. Full Binary Tree (Proper Binary Tree):**
- **Definition**: Every internal node has exactly 2 children
- **Property**: All nodes have either 0 or 2 children
- **No node has only one child**

```
    A
   / \
  B   C
 / \ / \
D  E F  G
```

**2. Complete Binary Tree:**
- **Definition**: All levels are filled except possibly the last level
- **Property**: Last level is filled from left to right
- **Used in**: Heap implementation

```
    A
   / \
  B   C
 / \ /
D  E F
```

**3. Perfect Binary Tree:**
- **Definition**: All internal nodes have 2 children and all leaves are at same level
- **Property**: Both full and complete
- **Number of nodes**: 2^(h+1) - 1 where h is height

```
    A
   / \
  B   C
 / \ / \
D  E F  G
```

**4. Balanced Binary Tree:**
- **Definition**: Height difference between left and right subtrees ≤ 1
- **Property**: For every node, |height(left) - height(right)| ≤ 1
- **Examples**: AVL trees, Red-Black trees

```
    A
   / \
  B   C
 /   / \
D   E   F
```

**5. Degenerate Binary Tree (Skewed Tree):**
- **Definition**: Each parent has only one child
- **Types**: Left-skewed or right-skewed
- **Performance**: Similar to linked list O(n)

```
Left-skewed:    Right-skewed:
A                   A
 \                   \
  B                   B
   \                   \
    C                   C
     \                   \
      D                   D
```

**6. Binary Search Tree (BST):**
- **Definition**: Left subtree < root < right subtree
- **Property**: Inorder traversal gives sorted sequence
- **Operations**: Search, insert, delete in O(log n) average

```
    10
   /  \
  5    15
 / \   / \
3   7 12  20
```

**Comparison Table:**
| Type | All Nodes | Leaf Nodes | Internal Nodes | Height |
|------|-----------|------------|----------------|--------|
| Full | 0 or 2 children | At same level | Exactly 2 children | Any |
| Complete | Fill level by level | Last level from left | Can have 1 or 2 children | Minimum possible |
| Perfect | 0 or 2 children | Same level | Exactly 2 children | log₂(n+1) - 1 |
| Balanced | Height difference ≤ 1 | Any level | 0, 1, or 2 children | O(log n) |
| Degenerate | 0 or 1 child | Any level | Exactly 1 child | O(n) |

**Properties:**
- **Full Binary Tree**: Number of leaf nodes = Number of internal nodes + 1
- **Complete Binary Tree**: Can be efficiently represented using arrays
- **Perfect Binary Tree**: Number of nodes = 2^(h+1) - 1
- **Balanced Binary Tree**: Guarantees O(log n) operations

---

### 42. What is tree traversal and what are its types? (Microsoft, Zoho)

**Answer:**
Tree traversal is the process of visiting each node in a tree data structure exactly once in a systematic way.

**Why Tree Traversal:**
- **Process all nodes**: Perform operations on each node
- **Search**: Find specific nodes or values
- **Copy/Clone**: Create copies of trees
- **Serialization**: Convert tree to linear representation
- **Expression evaluation**: Evaluate mathematical expressions

**Types of Tree Traversal:**

**1. Depth-First Search (DFS) Traversals:**
These traversals use a stack (either explicitly or recursively).

**a) Inorder Traversal (Left-Root-Right):**
- Visit left subtree
- Visit root
- Visit right subtree

**b) Preorder Traversal (Root-Left-Right):**
- Visit root
- Visit left subtree
- Visit right subtree

**c) Postorder Traversal (Left-Right-Root):**
- Visit left subtree
- Visit right subtree
- Visit root

**2. Breadth-First Search (BFS) Traversal:**
**Level Order Traversal:**
- Visit nodes level by level
- Uses queue data structure

**Example Tree:**
```
    A
   / \
  B   C
 / \ / \
D  E F  G
```

**Traversal Results:**
- **Inorder**: D, B, E, A, F, C, G
- **Preorder**: A, B, D, E, C, F, G
- **Postorder**: D, E, B, F, G, C, A
- **Level Order**: A, B, C, D, E, F, G

**Implementation Templates:**

**Recursive DFS:**
```c
void inorder(struct TreeNode* root) {
    if (root != NULL) {
        inorder(root->left);    // Left
        printf("%d ", root->data); // Root
        inorder(root->right);   // Right
    }
}

void preorder(struct TreeNode* root) {
    if (root != NULL) {
        printf("%d ", root->data); // Root
        preorder(root->left);   // Left
        preorder(root->right);  // Right
    }
}

void postorder(struct TreeNode* root) {
    if (root != NULL) {
        postorder(root->left);  // Left
        postorder(root->right); // Right
        printf("%d ", root->data); // Root
    }
}
```

**Iterative Level Order:**
```c
void levelOrder(struct TreeNode* root) {
    if (root == NULL) return;
    
    Queue q;
    initQueue(&q);
    enqueue(&q, root);
    
    while (!isEmpty(&q)) {
        struct TreeNode* node = dequeue(&q);
        printf("%d ", node->data);
        
        if (node->left) enqueue(&q, node->left);
        if (node->right) enqueue(&q, node->right);
    }
}
```

**Applications:**
- **Inorder**: Get sorted sequence (BST), expression evaluation
- **Preorder**: Copy tree, prefix expressions, tree serialization
- **Postorder**: Delete tree, postfix expressions, directory sizes
- **Level Order**: Print tree level by level, find height

**Time Complexity**: O(n) for all traversals
**Space Complexity**: O(h) for recursive (stack space), O(w) for level order (queue space)

---

### 43. What is inorder, preorder, and postorder traversal? (Facebook, Google)

**Answer:**

**Inorder Traversal (Left-Root-Right):**
**Algorithm:**
1. Traverse left subtree
2. Visit root node
3. Traverse right subtree

**Recursive Implementation:**
```c
void inorder(struct TreeNode* root) {
    if (root != NULL) {
        inorder(root->left);          // Step 1: Left subtree
        printf("%d ", root->data);    // Step 2: Root
        inorder(root->right);         // Step 3: Right subtree
    }
}
```

**Iterative Implementation:**
```c
void inorderIterative(struct TreeNode* root) {
    Stack stack;
    initStack(&stack);
    struct TreeNode* current = root;
    
    while (current != NULL || !isEmpty(&stack)) {
        // Go to leftmost node
        while (current != NULL) {
            push(&stack, current);
            current = current->left;
        }
        
        // Current is NULL, pop from stack
        current = pop(&stack);
        printf("%d ", current->data);
        
        // Visit right subtree
        current = current->right;
    }
}
```

**Preorder Traversal (Root-Left-Right):**
**Algorithm:**
1. Visit root node
2. Traverse left subtree
3. Traverse right subtree

**Recursive Implementation:**
```c
void preorder(struct TreeNode* root) {
    if (root != NULL) {
        printf("%d ", root->data);    // Step 1: Root
        preorder(root->left);         // Step 2: Left subtree
        preorder(root->right);        // Step 3: Right subtree
    }
}
```

**Iterative Implementation:**
```c
void preorderIterative(struct TreeNode* root) {
    if (root == NULL) return;
    
    Stack stack;
    initStack(&stack);
    push(&stack, root);
    
    while (!isEmpty(&stack)) {
        struct TreeNode* node = pop(&stack);
        printf("%d ", node->data);
        
        // Push right first, then left (stack is LIFO)
        if (node->right) push(&stack, node->right);
        if (node->left) push(&stack, node->left);
    }
}
```

**Postorder Traversal (Left-Right-Root):**
**Algorithm:**
1. Traverse left subtree
2. Traverse right subtree
3. Visit root node

**Recursive Implementation:**
```c
void postorder(struct TreeNode* root) {
    if (root != NULL) {
        postorder(root->left);        // Step 1: Left subtree
        postorder(root->right);       // Step 2: Right subtree
        printf("%d ", root->data);    // Step 3: Root
    }
}
```

**Iterative Implementation (Using Two Stacks):**
```c
void postorderIterative(struct TreeNode* root) {
    if (root == NULL) return;
    
    Stack stack1, stack2;
    initStack(&stack1);
    initStack(&stack2);
    
    push(&stack1, root);
    
    while (!isEmpty(&stack1)) {
        struct TreeNode* node = pop(&stack1);
        push(&stack2, node);
        
        if (node->left) push(&stack1, node->left);
        if (node->right) push(&stack1, node->right);
    }
    
    while (!isEmpty(&stack2)) {
        struct TreeNode* node = pop(&stack2);
        printf("%d ", node->data);
    }
}
```

**Example with Tree:**
```
    1
   / \
  2   3
 / \
4   5
```

**Step-by-step Execution:**

**Inorder (Left-Root-Right):**
1. Start at 1, go left to 2, go left to 4
2. Visit 4 (leaf), return to 2
3. Visit 2, go right to 5
4. Visit 5 (leaf), return to 2, return to 1
5. Visit 1, go right to 3
6. Visit 3 (leaf)
**Result**: 4, 2, 5, 1, 3

**Preorder (Root-Left-Right):**
1. Visit 1, go left to 2
2. Visit 2, go left to 4
3. Visit 4 (leaf), return to 2, go right to 5
4. Visit 5 (leaf), return to 2, return to 1, go right to 3
5. Visit 3 (leaf)
**Result**: 1, 2, 4, 5, 3

**Postorder (Left-Right-Root):**
1. Start at 1, go left to 2, go left to 4
2. Visit 4 (leaf), return to 2, go right to 5
3. Visit 5 (leaf), return to 2
4. Visit 2, return to 1, go right to 3
5. Visit 3 (leaf), return to 1
6. Visit 1
**Result**: 4, 5, 2, 3, 1

**Applications:**
- **Inorder**: Binary Search Tree gives sorted order
- **Preorder**: Tree copying, prefix expression evaluation
- **Postorder**: Tree deletion, postfix expression evaluation, directory size calculation

**Time Complexity**: O(n) - visit each node once
**Space Complexity**: O(h) - recursion stack depth equals tree height

---

### 44. What is level order traversal? (Amazon, Microsoft)

**Answer:**
Level order traversal (also called breadth-first traversal) visits all nodes at each level from left to right before moving to the next level.

**Algorithm:**
1. Start with root node
2. Visit all nodes at current level
3. Move to next level
4. Repeat until all levels are processed

**Uses Queue Data Structure:**
- **FIFO property**: Ensures level-by-level processing
- **Enqueue children**: Add left child first, then right child
- **Dequeue and process**: Remove node and visit its children

**Implementation:**
```c
#include <stdio.h>
#include <stdlib.h>

void levelOrder(struct TreeNode* root) {
    if (root == NULL) return;
    
    // Create queue for level order traversal
    Queue queue;
    initQueue(&queue);
    
    // Start with root
    enqueue(&queue, root);
    
    while (!isEmpty(&queue)) {
        struct TreeNode* current = dequeue(&queue);
        
        // Process current node
        printf("%d ", current->data);
        
        // Add children to queue (left first, then right)
        if (current->left != NULL) {
            enqueue(&queue, current->left);
        }
        if (current->right != NULL) {
            enqueue(&queue, current->right);
        }
    }
}
```

**Level-by-Level Printing:**
```c
void levelOrderWithLevels(struct TreeNode* root) {
    if (root == NULL) return;
    
    Queue queue;
    initQueue(&queue);
    enqueue(&queue, root);
    
    while (!isEmpty(&queue)) {
        int levelSize = getQueueSize(&queue);
        printf("Level: ");
        
        // Process all nodes at current level
        for (int i = 0; i < levelSize; i++) {
            struct TreeNode* node = dequeue(&queue);
            printf("%d ", node->data);
            
            if (node->left) enqueue(&queue, node->left);
            if (node->right) enqueue(&queue, node->right);
        }
        printf("\n");
    }
}
```

**Example:**
```
Tree:
    1
   / \
  2   3
 / \ / \
4  5 6  7

Level Order: 1 2 3 4 5 6 7

Level-by-Level:
Level 0: 1
Level 1: 2 3
Level 2: 4 5 6 7
```

**Step-by-Step Execution:**
```
Initial: Queue = [1]
Step 1: Dequeue 1, print 1, enqueue 2,3 → Queue = [2,3]
Step 2: Dequeue 2, print 2, enqueue 4,5 → Queue = [3,4,5]
Step 3: Dequeue 3, print 3, enqueue 6,7 → Queue = [4,5,6,7]
Step 4: Dequeue 4, print 4, no children → Queue = [5,6,7]
Step 5: Dequeue 5, print 5, no children → Queue = [6,7]
Step 6: Dequeue 6, print 6, no children → Queue = [7]
Step 7: Dequeue 7, print 7, no children → Queue = []
```

**Variations:**

**1. Right to Left Level Order:**
```c
void levelOrderRightToLeft(struct TreeNode* root) {
    if (root == NULL) return;
    
    Queue queue;
    initQueue(&queue);
    enqueue(&queue, root);
    
    while (!isEmpty(&queue)) {
        struct TreeNode* node = dequeue(&queue);
        printf("%d ", node->data);
        
        // Add right child first, then left child
        if (node->right) enqueue(&queue, node->right);
        if (node->left) enqueue(&queue, node->left);
    }
}
```

**2. Zigzag Level Order:**
```c
void zigzagLevelOrder(struct TreeNode* root) {
    if (root == NULL) return;
    
    Stack stack1, stack2;
    initStack(&stack1);
    initStack(&stack2);
    
    push(&stack1, root);
    bool leftToRight = true;
    
    while (!isEmpty(&stack1) || !isEmpty(&stack2)) {
        if (leftToRight) {
            while (!isEmpty(&stack1)) {
                struct TreeNode* node = pop(&stack1);
                printf("%d ", node->data);
                
                if (node->left) push(&stack2, node->left);
                if (node->right) push(&stack2, node->right);
            }
        } else {
            while (!isEmpty(&stack2)) {
                struct TreeNode* node = pop(&stack2);
                printf("%d ", node->data);
                
                if (node->right) push(&stack1, node->right);
                if (node->left) push(&stack1, node->left);
            }
        }
        leftToRight = !leftToRight;
    }
}
```

**Applications:**
- **Tree printing**: Display tree structure level by level
- **Finding height**: Count number of levels
- **Finding width**: Maximum nodes at any level
- **Level-wise processing**: Process nodes at each level
- **Serialization**: Convert tree to array representation
- **Complete tree check**: Verify if tree is complete

**Time Complexity**: O(n) - visit each node once
**Space Complexity**: O(w) - maximum width of tree (queue size)

**Comparison with DFS:**
- **Level Order (BFS)**: Uses queue, processes level by level
- **DFS**: Uses stack/recursion, goes deep first
- **Memory usage**: BFS uses more memory for wide trees
- **Applications**: BFS for shortest path, DFS for exhaustive search

---

### 45. What are the applications of trees? (Zoho, Facebook)

**Answer:**

**1. File Systems:**
- **Directory structure**: Hierarchical organization of files and folders
- **Path representation**: Navigate through directory trees
- **File operations**: Create, delete, move files/folders
- **Permissions**: Inherit permissions from parent directories

**Example:**
```
Root (/)
├── home/
│   ├── user1/
│   │   ├── documents/
│   │   └── pictures/
│   └── user2/
├── etc/
└── var/
```

**2. Database Systems:**
- **B-trees**: Efficient disk-based storage and retrieval
- **B+ trees**: Database indexing for faster queries
- **Binary search trees**: In-memory indexing
- **Decision trees**: Query optimization

**3. Compiler Design:**
- **Parse trees**: Syntax analysis of programming languages
- **Abstract syntax trees (AST)**: Intermediate representation
- **Expression trees**: Mathematical expression evaluation
- **Symbol tables**: Variable and function management

**Example - Expression Tree:**
```
Expression: (a + b) * (c - d)
Tree:
    *
   / \
  +   -
 / \ / \
a  b c  d
```

**4. Artificial Intelligence:**
- **Decision trees**: Machine learning algorithms
- **Game trees**: Minimax algorithm for game playing
- **Search trees**: A* algorithm for pathfinding
- **Knowledge representation**: Expert systems

**5. Computer Graphics:**
- **Scene graphs**: 3D object hierarchy
- **Quadtrees**: 2D spatial partitioning
- **Octrees**: 3D spatial partitioning
- **BSP trees**: Binary space partitioning

**6. Network Routing:**
- **Spanning trees**: Network topology without cycles
- **Shortest path trees**: Routing algorithms
- **Multicast trees**: Efficient data distribution
- **Routing tables**: Hierarchical routing

**7. Operating Systems:**
- **Process trees**: Parent-child process relationships
- **Memory management**: Buddy system allocation
- **File allocation**: Inode structures
- **Priority scheduling**: Heap-based priority queues

**8. Data Compression:**
- **Huffman trees**: Optimal prefix codes
- **LZ77/LZ78**: Dictionary-based compression
- **Arithmetic coding**: Statistical compression
- **JPEG compression**: DCT trees

**9. Web Technologies:**
- **DOM trees**: HTML document structure
- **XML parsing**: Hierarchical data representation
- **JSON parsing**: Nested object structures
- **Website navigation**: Sitemap hierarchies

**10. Bioinformatics:**
- **Phylogenetic trees**: Evolutionary relationships
- **Suffix trees**: String matching algorithms
- **Gene expression**: Hierarchical clustering
- **Protein structure**: Molecular hierarchies

**Specific Tree Applications:**

**Binary Search Trees (BST):**
- **Search operations**: O(log n) average case
- **Database indexing**: Ordered data retrieval
- **Auto-complete**: Word suggestions
- **Range queries**: Find elements in a range

**Heap Trees:**
- **Priority queues**: Task scheduling
- **Heap sort**: Efficient sorting algorithm
- **Dijkstra's algorithm**: Shortest path finding
- **Huffman coding**: Data compression

**AVL/Red-Black Trees:**
- **Self-balancing**: Guaranteed O(log n) operations
- **Database systems**: Consistent performance
- **Language libraries**: Standard library implementations
- **Real-time systems**: Predictable response times

**Trie Trees:**
- **Auto-complete**: Word suggestions
- **Spell checkers**: Dictionary lookups
- **IP routing**: Longest prefix matching
- **Genome sequencing**: DNA pattern matching

**Segment Trees:**
- **Range queries**: Sum, minimum, maximum over ranges
- **Computational geometry**: Geometric algorithms
- **Image processing**: Region-based operations
- **Statistics**: Dynamic range computations

**Code Example - File System Tree:**
```c
struct FileNode {
    char name[256];
    bool isDirectory;
    struct FileNode* parent;
    struct FileNode* children;
    struct FileNode* sibling;
    long size;
    time_t modified;
};

// Navigate to file
struct FileNode* findFile(struct FileNode* root, char* path) {
    // Split path and traverse tree
    struct FileNode* current = root;
    char* token = strtok(path, "/");
    
    while (token != NULL) {
        current = findChild(current, token);
        if (current == NULL) return NULL;
        token = strtok(NULL, "/");
    }
    return current;
}
```

**Performance Benefits:**
- **Logarithmic operations**: O(log n) for balanced trees
- **Hierarchical organization**: Natural data representation
- **Efficient searching**: Better than linear data structures
- **Memory efficient**: Only store necessary connections
- **Scalability**: Handle large datasets efficiently

**Real-world Impact:**
- **Database performance**: Faster query execution
- **File system efficiency**: Quick file access
- **Network optimization**: Efficient routing
- **AI decision making**: Structured problem solving
- **Compression ratios**: Smaller file sizes

---

## HASH TABLES

### 46. What is a hash table? (Google, Amazon)

**Answer:**
A hash table (also called hash map) is a data structure that implements an associative array abstract data type, mapping keys to values using a hash function.

**Key Concepts:**
- **Hash function**: Transforms keys into array indices
- **Key-value pairs**: Store data as (key, value) combinations
- **Direct access**: O(1) average time complexity for operations
- **Collision handling**: Manage multiple keys mapping to same index

**Basic Structure:**
```
Hash Table = Array + Hash Function + Collision Resolution

Keys: ["apple", "banana", "cherry"]
Hash Function: h(key) = sum of ASCII values % table_size
Hash Table: [empty, "apple"->5, empty, "banana"->12, "cherry"->8]
```

**Hash Function:**
```c
int hashFunction(char* key, int tableSize) {
    int hash = 0;
    for (int i = 0; key[i] != '\0'; i++) {
        hash += key[i];
    }
    return hash % tableSize;
}
```

**Basic Implementation:**
```c
#define TABLE_SIZE 10

typedef struct HashNode {
    char* key;
    int value;
    struct HashNode* next;  // For chaining
} HashNode;

typedef struct {
    HashNode* table[TABLE_SIZE];
} HashTable;

// Initialize hash table
void initHashTable(HashTable* ht) {
    for (int i = 0; i < TABLE_SIZE; i++) {
        ht->table[i] = NULL;
    }
}

// Insert key-value pair
void insert(HashTable* ht, char* key, int value) {
    int index = hashFunction(key, TABLE_SIZE);
    
    // Create new node
    HashNode* newNode = (HashNode*)malloc(sizeof(HashNode));
    newNode->key = strdup(key);
    newNode->value = value;
    newNode->next = ht->table[index];
    
    // Insert at beginning (chaining)
    ht->table[index] = newNode;
}

// Search for key
int search(HashTable* ht, char* key) {
    int index = hashFunction(key, TABLE_SIZE);
    HashNode* current = ht->table[index];
    
    while (current != NULL) {
        if (strcmp(current->key, key) == 0) {
            return current->value;
        }
        current = current->next;
    }
    return -1;  // Key not found
}

// Delete key
bool delete(HashTable* ht, char* key) {
    int index = hashFunction(key, TABLE_SIZE);
    HashNode* current = ht->table[index];
    HashNode* prev = NULL;
    
    while (current != NULL) {
        if (strcmp(current->key, key) == 0) {
            if (prev == NULL) {
                ht->table[index] = current->next;
            } else {
                prev->next = current->next;
            }
            free(current->key);
            free(current);
            return true;
        }
        prev = current;
        current = current->next;
    }
    return false;  // Key not found
}
```

**Operations:**
- **Insert**: Add key-value pair
- **Search**: Find value by key
- **Delete**: Remove key-value pair
- **Update**: Modify existing value

**Time Complexity:**
- **Average case**: O(1) for all operations
- **Worst case**: O(n) when all keys hash to same index
- **Space complexity**: O(n) for n key-value pairs

**Load Factor:**
- **Definition**: Number of entries / Table size
- **Optimal range**: 0.7 to 0.8 for good performance
- **Resizing**: When load factor exceeds threshold

**Applications:**
- **Database indexing**: Fast record retrieval
- **Caches**: Web caches, CPU caches
- **Symbol tables**: Compiler design
- **Dictionaries**: Word lookup, spell checkers
- **Sets**: Unique element storage
- **Associative arrays**: Programming language implementations

**Real-world Examples:**
- **Python dictionaries**: Built-in hash table implementation
- **Java HashMap**: Standard library hash table
- **Database indexes**: B-tree with hash indexing
- **Web caching**: URL to cached content mapping
- **DNS resolution**: Domain name to IP address

**Hash Table vs Other Data Structures:**
| Operation | Hash Table | Array | Linked List | BST |
|-----------|------------|--------|-------------|-----|
| Search | O(1) avg | O(n) | O(n) | O(log n) |
| Insert | O(1) avg | O(n) | O(1) | O(log n) |
| Delete | O(1) avg | O(n) | O(n) | O(log n) |
| Space | O(n) | O(n) | O(n) | O(n) |

---

### 47. What is a hash function? (Microsoft, Zoho)

**Answer:**
A hash function is a mathematical function that converts input data (keys) of arbitrary size into fixed-size values (hash codes) that serve as indices in a hash table.

**Key Properties:**
- **Deterministic**: Same input always produces same output
- **Uniform distribution**: Spreads keys evenly across hash table
- **Efficient**: Fast computation, typically O(1)
- **Avalanche effect**: Small input changes cause large output changes

**Basic Hash Function Examples:**

**1. Division Method:**
```c
int divisionHash(int key, int tableSize) {
    return key % tableSize;
}
```

**2. Multiplication Method:**
```c
int multiplicationHash(int key, int tableSize) {
    double A = 0.6180339887;  // (√5 - 1) / 2
    double product = key * A;
    double fractional = product - (int)product;
    return (int)(tableSize * fractional);
}
```

**3. String Hash Functions:**

**Simple ASCII Sum:**
```c
int simpleStringHash(char* key, int tableSize) {
    int hash = 0;
    for (int i = 0; key[i] != '\0'; i++) {
        hash += key[i];
    }
    return hash % tableSize;
}
```

**Polynomial Hash (Horner's Method):**
```c
int polynomialHash(char* key, int tableSize) {
    int hash = 0;
    int prime = 31;  // Common prime number
    
    for (int i = 0; key[i] != '\0'; i++) {
        hash = (hash * prime + key[i]) % tableSize;
    }
    return hash;
}
```

**djb2 Hash Function:**
```c
unsigned long djb2Hash(char* key) {
    unsigned long hash = 5381;
    int c;
    
    while ((c = *key++)) {
        hash = ((hash << 5) + hash) + c; // hash * 33 + c
    }
    return hash;
}
```

**4. Cryptographic Hash Functions:**
- **MD5**: 128-bit hash (not recommended for security)
- **SHA-1**: 160-bit hash (deprecated for security)
- **SHA-256**: 256-bit hash (secure)
- **SHA-3**: Latest standard

**Hash Function Design Criteria:**

**1. Uniform Distribution:**
- Keys should be distributed evenly across hash table
- Minimizes clustering and collisions
- Statistical randomness in output

**2. Avalanche Effect:**
- Small changes in input cause large changes in output
- Good for security and distribution

**3. Computational Efficiency:**
- Fast to compute
- Simple operations (addition, multiplication, bitwise)
- Minimal memory usage

**4. Deterministic:**
- Same input always produces same output
- Reproducible results

**Common Hash Function Issues:**

**1. Clustering:**
- Keys map to adjacent indices
- Degraded performance
- Solution: Better hash function or open addressing

**2. Poor Distribution:**
- Some indices get more keys than others
- Uneven load distribution
- Solution: Universal hashing

**3. Collision Frequency:**
- Multiple keys map to same index
- Requires collision resolution
- Solution: Good hash function design

**Universal Hashing:**
```c
typedef struct {
    int a, b, p, m;
} UniversalHashFunction;

int universalHash(UniversalHashFunction* h, int key) {
    return ((h->a * key + h->b) % h->p) % h->m;
}

// Initialize with random parameters
void initUniversalHash(UniversalHashFunction* h, int tableSize) {
    h->m = tableSize;
    h->p = nextPrime(tableSize * 2);  // Large prime
    h->a = rand() % (h->p - 1) + 1;   // Random 1 to p-1
    h->b = rand() % h->p;             // Random 0 to p-1
}
```

**Hash Function Selection Guidelines:**

**For Integers:**
- **Division method**: Simple, good for prime table sizes
- **Multiplication method**: Good distribution, any table size
- **Universal hashing**: Theoretically optimal

**For Strings:**
- **Polynomial hash**: Good distribution, fast
- **djb2**: Excellent practical performance
- **FNV hash**: Good for short strings

**For Cryptographic Use:**
- **SHA-256**: Secure, collision-resistant
- **SHA-3**: Latest standard, quantum-resistant
- **Blake2**: Fast, secure alternative

**Performance Comparison:**
| Hash Function | Speed | Distribution | Collision Rate |
|---------------|-------|--------------|----------------|
| Simple sum | Very fast | Poor | High |
| Division | Fast | Good | Medium |
| Multiplication | Fast | Good | Medium |
| Polynomial | Medium | Excellent | Low |
| djb2 | Fast | Excellent | Low |
| Cryptographic | Slow | Excellent | Very low |

**Example Usage:**
```c
// Hash table with different hash functions
HashTable ht;
initHashTable(&ht);

// Using polynomial hash
int index1 = polynomialHash("apple", TABLE_SIZE);
int index2 = polynomialHash("banana", TABLE_SIZE);

// Insert with computed indices
insert(&ht, "apple", 5);
insert(&ht, "banana", 12);
```

**Quality Metrics:**
- **Avalanche ratio**: Percentage of output bits that change
- **Distribution chi-square**: Statistical uniformity test
- **Collision rate**: Frequency of hash collisions
- **Performance**: Operations per second

---

### 48. What is collision in hashing? (Facebook, Google)

**Answer:**
A collision in hashing occurs when two or more different keys are mapped to the same hash table index by the hash function.

**Why Collisions Occur:**
- **Finite table size**: Limited number of indices available
- **Infinite key space**: Unlimited possible keys
- **Pigeonhole principle**: If you have more keys than indices, collisions are inevitable
- **Hash function limitations**: Even perfect distribution has collisions

**Mathematical Perspective:**
- **Birthday paradox**: With only 23 people, 50% chance of shared birthday
- **Hash table**: With √n random keys, 50% chance of collision
- **Load factor**: Higher load factor = more collisions

**Types of Collisions:**

**1. Direct Collision:**
```c
hash("apple") = 5
hash("grape") = 5
// Both keys map to index 5
```

**2. Cluster Collision:**
```c
hash("key1") = 3
hash("key2") = 3
hash("key3") = 3
// Multiple keys cluster at same index
```

**Example:**
```c
// Simple hash function
int simpleHash(char* key, int tableSize) {
    int sum = 0;
    for (int i = 0; key[i] != '\0'; i++) {
        sum += key[i];
    }
    return sum % tableSize;
}

// These keys will collide:
// "abc" -> (97+98+99) % 7 = 294 % 7 = 0
// "bac" -> (98+97+99) % 7 = 294 % 7 = 0
// "cab" -> (99+97+98) % 7 = 294 % 7 = 0
```

**Collision Resolution Techniques:**

**1. Chaining (Separate Chaining):**
- Store multiple elements at same index using linked lists
- Each hash table slot points to a linked list
- Simple to implement and understand

```c
typedef struct Node {
    char* key;
    int value;
    struct Node* next;
} Node;

typedef struct {
    Node* table[TABLE_SIZE];
} HashTable;

void insertChaining(HashTable* ht, char* key, int value) {
    int index = hashFunction(key, TABLE_SIZE);
    
    // Create new node
    Node* newNode = (Node*)malloc(sizeof(Node));
    newNode->key = strdup(key);
    newNode->value = value;
    newNode->next = ht->table[index];
    
    // Insert at beginning
    ht->table[index] = newNode;
}
```

**2. Open Addressing:**
- Find alternative empty slot when collision occurs
- All elements stored in hash table itself
- Several probing techniques available

**a) Linear Probing:**
```c
int linearProbe(int hash, int i, int tableSize) {
    return (hash + i) % tableSize;
}

void insertLinearProbing(HashTable* ht, char* key, int value) {
    int hash = hashFunction(key, TABLE_SIZE);
    int i = 0;
    
    while (ht->table[(hash + i) % TABLE_SIZE].occupied) {
        i++;
        if (i == TABLE_SIZE) {
            printf("Table full!\n");
            return;
        }
    }
    
    int index = (hash + i) % TABLE_SIZE;
    ht->table[index].key = strdup(key);
    ht->table[index].value = value;
    ht->table[index].occupied = true;
}
```

**b) Quadratic Probing:**
```c
int quadraticProbe(int hash, int i, int tableSize) {
    return (hash + i * i) % tableSize;
}
```

**c) Double Hashing:**
```c
int doubleHash(char* key, int i, int tableSize) {
    int hash1 = hashFunction1(key, tableSize);
    int hash2 = hashFunction2(key, tableSize);
    return (hash1 + i * hash2) % tableSize;
}
```

**Collision Resolution Comparison:**

| Method | Advantages | Disadvantages |
|--------|------------|---------------|
| **Chaining** | Simple, handles high load factor | Extra memory for pointers |
| **Linear Probing** | Cache-friendly, no extra memory | Clustering problems |
| **Quadratic Probing** | Reduces clustering | May not find empty slot |
| **Double Hashing** | Uniform distribution | Complex implementation |

**Performance Impact:**

**Chaining:**
- **Search time**: O(1 + α) where α is load factor
- **Load factor**: Can exceed 1.0
- **Memory**: Extra space for pointers

**Open Addressing:**
- **Search time**: O(1/(1-α)) for α < 1
- **Load factor**: Must be < 1.0
- **Memory**: No extra space for pointers

**Collision Analysis:**
```c
// Measure collision statistics
typedef struct {
    int totalCollisions;
    int maxChainLength;
    int emptySlots;
    double loadFactor;
} CollisionStats;

CollisionStats analyzeCollisions(HashTable* ht) {
    CollisionStats stats = {0, 0, 0, 0.0};
    int totalElements = 0;
    
    for (int i = 0; i < TABLE_SIZE; i++) {
        int chainLength = 0;
        Node* current = ht->table[i];
        
        while (current != NULL) {
            chainLength++;
            totalElements++;
            current = current->next;
        }
        
        if (chainLength == 0) {
            stats.emptySlots++;
        } else if (chainLength > 1) {
            stats.totalCollisions += (chainLength - 1);
        }
        
        if (chainLength > stats.maxChainLength) {
            stats.maxChainLength = chainLength;
        }
    }
    
    stats.loadFactor = (double)totalElements / TABLE_SIZE;
    return stats;
}
```

**Minimizing Collisions:**

**1. Good Hash Function:**
- Uniform distribution
- Avalanche effect
- Appropriate for data type

**2. Appropriate Table Size:**
- Prime numbers often work well
- Power of 2 for bitwise operations
- Size relative to expected number of keys

**3. Load Factor Management:**
- Keep load factor reasonable (< 0.75)
- Resize table when load factor exceeds threshold
- Rehash all elements after resizing

**4. Dynamic Resizing:**
```c
void resizeHashTable(HashTable* ht) {
    int oldSize = ht->size;
    Node** oldTable = ht->table;
    
    // Double the size
    ht->size = oldSize * 2;
    ht->table = (Node**)calloc(ht->size, sizeof(Node*));
    
    // Rehash all elements
    for (int i = 0; i < oldSize; i++) {
        Node* current = oldTable[i];
        while (current != NULL) {
            Node* next = current->next;
            
            // Rehash and insert
            int newIndex = hashFunction(current->key, ht->size);
            current->next = ht->table[newIndex];
            ht->table[newIndex] = current;
            
            current = next;
        }
    }
    
    free(oldTable);
}
```

**Real-world Considerations:**
- **Database systems**: Use B-trees to minimize disk I/O
- **Caching systems**: LRU eviction to handle collisions
- **Distributed systems**: Consistent hashing for load balancing
- **Security**: Collision attacks on hash functions

---

### 49. What are collision resolution techniques? (Amazon, Microsoft)

**Answer:**
Collision resolution techniques are methods used to handle situations where multiple keys hash to the same index in a hash table.

**Two Main Categories:**

## 1. SEPARATE CHAINING (CLOSED ADDRESSING)

**Concept**: Store multiple elements at the same index using additional data structures.

**Implementation Methods:**

**a) Linked List Chaining:**
```c
typedef struct Node {
    char* key;
    int value;
    struct Node* next;
} Node;

typedef struct {
    Node* table[TABLE_SIZE];
    int size;
} HashTable;

void insertChaining(HashTable* ht, char* key, int value) {
    int index = hashFunction(key, TABLE_SIZE);
    
    // Check if key already exists
    Node* current = ht->table[index];
    while (current != NULL) {
        if (strcmp(current->key, key) == 0) {
            current->value = value;  // Update existing
            return;
        }
        current = current->next;
    }
    
    // Create new node and insert at beginning
    Node* newNode = (Node*)malloc(sizeof(Node));
    newNode->key = strdup(key);
    newNode->value = value;
    newNode->next = ht->table[index];
    ht->table[index] = newNode;
    ht->size++;
}

int searchChaining(HashTable* ht, char* key) {
    int index = hashFunction(key, TABLE_SIZE);
    Node* current = ht->table[index];
    
    while (current != NULL) {
        if (strcmp(current->key, key) == 0) {
            return current->value;
        }
        current = current->next;
    }
    return -1;  // Not found
}
```

**b) Dynamic Array Chaining:**
```c
typedef struct {
    char** keys;
    int* values;
    int capacity;
    int size;
} Bucket;

typedef struct {
    Bucket* table[TABLE_SIZE];
} HashTable;

void insertBucket(HashTable* ht, char* key, int value) {
    int index = hashFunction(key, TABLE_SIZE);
    
    if (ht->table[index] == NULL) {
        ht->table[index] = createBucket();
    }
    
    addToBucket(ht->table[index], key, value);
}
```

**c) Self-Balancing Tree Chaining:**
```c
// Use AVL tree or Red-Black tree for each bucket
typedef struct {
    TreeNode* table[TABLE_SIZE];
} HashTable;

void insertTree(HashTable* ht, char* key, int value) {
    int index = hashFunction(key, TABLE_SIZE);
    ht->table[index] = insertAVL(ht->table[index], key, value);
}
```

## 2. OPEN ADDRESSING (CLOSED HASHING)

**Concept**: Find alternative empty slots within the hash table when collision occurs.

**a) Linear Probing:**
```c
typedef struct {
    char* key;
    int value;
    bool occupied;
    bool deleted;  // For lazy deletion
} HashEntry;

typedef struct {
    HashEntry* table;
    int size;
    int capacity;
} HashTable;

void insertLinearProbing(HashTable* ht, char* key, int value) {
    int hash = hashFunction(key, ht->capacity);
    int index = hash;
    
    while (ht->table[index].occupied && !ht->table[index].deleted) {
        if (strcmp(ht->table[index].key, key) == 0) {
            ht->table[index].value = value;  // Update
            return;
        }
        index = (index + 1) % ht->capacity;  // Linear probe
        
        if (index == hash) {  // Table full
            printf("Hash table full!\n");
            return;
        }
    }
    
    // Insert at found position
    ht->table[index].key = strdup(key);
    ht->table[index].value = value;
    ht->table[index].occupied = true;
    ht->table[index].deleted = false;
    ht->size++;
}

int searchLinearProbing(HashTable* ht, char* key) {
    int hash = hashFunction(key, ht->capacity);
    int index = hash;
    
    while (ht->table[index].occupied || ht->table[index].deleted) {
        if (ht->table[index].occupied && !ht->table[index].deleted &&
            strcmp(ht->table[index].key, key) == 0) {
            return ht->table[index].value;
        }
        index = (index + 1) % ht->capacity;
        
        if (index == hash) break;  // Full cycle
    }
    return -1;  // Not found
}
```

**b) Quadratic Probing:**
```c
int quadraticProbe(int hash, int i, int capacity) {
    return (hash + i * i) % capacity;
}

void insertQuadraticProbing(HashTable* ht, char* key, int value) {
    int hash = hashFunction(key, ht->capacity);
    int i = 0;
    
    while (i < ht->capacity) {
        int index = (hash + i * i) % ht->capacity;
        
        if (!ht->table[index].occupied || ht->table[index].deleted) {
            ht->table[index].key = strdup(key);
            ht->table[index].value = value;
            ht->table[index].occupied = true;
            ht->table[index].deleted = false;
            ht->size++;
            return;
        }
        
        if (strcmp(ht->table[index].key, key) == 0) {
            ht->table[index].value = value;  // Update
            return;
        }
        
        i++;
    }
    printf("Could not insert - table full or no valid position!\n");
}
```

**c) Double Hashing:**
```c
int hashFunction2(char* key, int capacity) {
    // Second hash function should be relatively prime to capacity
    int hash = 0;
    for (int i = 0; key[i] != '\0'; i++) {
        hash = (hash * 31 + key[i]) % capacity;
    }
    return 7 - (hash % 7);  // Ensure it's never 0
}

void insertDoubleHashing(HashTable* ht, char* key, int value) {
    int hash1 = hashFunction(key, ht->capacity);
    int hash2 = hashFunction2(key, ht->capacity);
    int index = hash1;
    int i = 0;
    
    while (ht->table[index].occupied && !ht->table[index].deleted) {
        if (strcmp(ht->table[index].key, key) == 0) {
            ht->table[index].value = value;  // Update
            return;
        }
        
        i++;
        index = (hash1 + i * hash2) % ht->capacity;
        
        if (i == ht->capacity) {
            printf("Hash table full!\n");
            return;
        }
    }
    
    // Insert at found position
    ht->table[index].key = strdup(key);
    ht->table[index].value = value;
    ht->table[index].occupied = true;
    ht->table[index].deleted = false;
    ht->size++;
}
```

**Comparison of Techniques:**

| Technique | Time Complexity | Space Overhead | Clustering | Load Factor Limit |
|-----------|-----------------|----------------|------------|-------------------|
| **Separate Chaining** | O(1 + α) | High (pointers) | None | None (can exceed 1) |
| **Linear Probing** | O(1/(1-α)) | None | High | < 1.0 |
| **Quadratic Probing** | O(1/(1-α)) | None | Moderate | < 0.5 |
| **Double Hashing** | O(1/(1-α)) | None | Low | < 1.0 |

**Advanced Techniques:**

**1. Robin Hood Hashing:**
```c
typedef struct {
    char* key;
    int value;
    int distance;  // Distance from ideal position
} RobinHoodEntry;

void insertRobinHood(HashTable* ht, char* key, int value) {
    int hash = hashFunction(key, ht->capacity);
    int distance = 0;
    
    while (true) {
        int index = (hash + distance) % ht->capacity;
        
        if (!ht->table[index].occupied) {
            // Empty slot found
            ht->table[index].key = strdup(key);
            ht->table[index].value = value;
            ht->table[index].distance = distance;
            ht->table[index].occupied = true;
            return;
        }
        
        if (distance > ht->table[index].distance) {
            // Current entry is closer to its ideal position
            // Swap with the "richer" entry
            swapEntries(&ht->table[index], key, value, distance);
            // Continue with the evicted entry
        }
        
        distance++;
    }
}
```

**2. Cuckoo Hashing:**
```c
typedef struct {
    HashEntry* table1;
    HashEntry* table2;
    int capacity;
    int size;
} CuckooHashTable;

bool insertCuckoo(CuckooHashTable* ht, char* key, int value) {
    int hash1 = hashFunction1(key, ht->capacity);
    int hash2 = hashFunction2(key, ht->capacity);
    
    // Try first table
    if (!ht->table1[hash1].occupied) {
        ht->table1[hash1].key = strdup(key);
        ht->table1[hash1].value = value;
        ht->table1[hash1].occupied = true;
        return true;
    }
    
    // Try second table
    if (!ht->table2[hash2].occupied) {
        ht->table2[hash2].key = strdup(key);
        ht->table2[hash2].value = value;
        ht->table2[hash2].occupied = true;
        return true;
    }
    
    // Perform cuckoo eviction
    return cuckooEvict(ht, key, value, hash1, hash2);
}
```

**Selection Guidelines:**

**Choose Separate Chaining when:**
- Unknown number of elements
- High load factors expected
- Simple implementation preferred
- Memory is not a major concern

**Choose Open Addressing when:**
- Better cache performance needed
- Memory usage must be minimized
- Load factor can be controlled
- Deletion is infrequent

**Choose specific probing method based on:**
- **Linear probing**: Best cache performance, simple
- **Quadratic probing**: Moderate performance, avoids clustering
- **Double hashing**: Best distribution, complex implementation

**Performance Optimization:**
- **Load factor monitoring**: Resize when threshold exceeded
- **Hash function quality**: Use well-distributed functions
- **Table size selection**: Prime numbers for better distribution
- **Lazy deletion**: Mark as deleted instead of actual removal
